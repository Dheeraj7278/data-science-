{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35381e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape  (506, 13)\n",
      "y.shape  (506,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # importing numpy for numerical computation\n",
    "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
    "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n",
    "\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "boston = load_boston()\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable\n",
    "\n",
    "print(\"x.shape \", x.shape)\n",
    "print(\"y.shape \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1d90832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
       "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
       "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9690e+02, 5.3300e+00],\n",
       "       [2.9850e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
       "        6.4300e+00, 5.8700e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
       "        1.8700e+01, 3.9412e+02, 5.2100e+00],\n",
       "       [8.8290e-02, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01,\n",
       "        6.0120e+00, 6.6600e+01, 5.5605e+00, 5.0000e+00, 3.1100e+02,\n",
       "        1.5200e+01, 3.9560e+02, 1.2430e+01],\n",
       "       [1.4455e-01, 1.2500e+01, 7.8700e+00, 0.0000e+00, 5.2400e-01,\n",
       "        6.1720e+00, 9.6100e+01, 5.9505e+00, 5.0000e+00, 3.1100e+02,\n",
       "        1.5200e+01, 3.9690e+02, 1.9150e+01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34eebe",
   "metadata": {},
   "source": [
    "# Step - 1 - Creating samples\n",
    "\n",
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cd2518",
   "metadata": {},
   "source": [
    "Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b9fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_samples(input_data, target_data): \n",
    "  \n",
    "  # random.choice to generate random indices without replacement\n",
    "  # selecting 303 random row indices from the input_data, without replacement\n",
    "  rows_selected = np.random.choice(len(input_data), 303, replace=False)\n",
    "  \n",
    "  # now we will replicate 203 points from above selected rows\n",
    "  # Replacing Rows => Extracting 206 reandom row indices from the abvoe rows_selected\n",
    "  rows_203_extracted_from_rows_selected = np.random.choice(rows_selected, 203, replace=False)\n",
    "  \n",
    "  # Now get 3 to 13 random column indices from input_data\n",
    "  number_of_columns_to_select = random.randint(3, 13)\n",
    "  columns_selected = np.array(random.sample(range(0, 13), number_of_columns_to_select ))\n",
    "  \n",
    "  sample_data = input_data[rows_selected[:, None], columns_selected]\n",
    "  \n",
    "  target_of_sample_data = target_data[rows_selected]\n",
    "  \n",
    "  # Now Replication of Data for 203 data points out of 303 selected points\n",
    "  \n",
    "  replicated_203_sample_data_points = input_data[rows_203_extracted_from_rows_selected[:, None], columns_selected ]\n",
    "  \n",
    "  target_203_replicated_sample_data = target_data[rows_203_extracted_from_rows_selected]\n",
    "  \n",
    "  # Concatenating data\n",
    "  \n",
    "  final_sample_data = np.vstack((sample_data, replicated_203_sample_data_points ))\n",
    "  \n",
    "  final_target_data = np.vstack((target_of_sample_data.reshape(-1, 1), target_203_replicated_sample_data.reshape(-1, 1) ))\n",
    "  \n",
    "  return final_sample_data, final_target_data, rows_selected, columns_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600db932",
   "metadata": {},
   "source": [
    "# Grader function - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c872136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 5)\n",
      "(506, 1)\n",
      "(303,)\n",
      "(5,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_samples(a,b,c,d):\n",
    "    length = (len(a)==506  and len(b)==506)\n",
    "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
    "    rows_length = (len(c)==303)\n",
    "    column_length= (len(d)>=3)\n",
    "    assert(length and sampled and rows_length and column_length)\n",
    "    return True\n",
    "  \n",
    "a,b,c,d = generating_samples(x, y)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "grader_samples(a,b,c,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f5439",
   "metadata": {},
   "source": [
    "# Creating 30 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a312c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use generating_samples function to create 30 samples \n",
    "# store these created samples in a list\n",
    "list_input_data =[]\n",
    "list_output_data =[]\n",
    "list_selected_row= []\n",
    "list_selected_columns=[]\n",
    "\n",
    "for i in range (0, 30):\n",
    "  a, b, c, d = generating_samples(x, y)\n",
    "  list_input_data.append(a)\n",
    "  list_output_data.append(b)\n",
    "  list_selected_row.append(c)\n",
    "  list_selected_columns.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5e006",
   "metadata": {},
   "source": [
    "# Grader function - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c54965f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_30(a):\n",
    "    assert(len(a)==30 and len(a[0])==506)\n",
    "    return True\n",
    "grader_30(list_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d578a",
   "metadata": {},
   "source": [
    "# Step - 2 of Task-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d36bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_models_decision_tree = []\n",
    "for i in range(0, 30):\n",
    "  model_i = DecisionTreeRegressor(max_depth=None)\n",
    "  model_i.fit(list_input_data[i], list_output_data[i])\n",
    "  list_of_all_models_decision_tree.append(model_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb90aa6",
   "metadata": {},
   "source": [
    "# Calculating MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "556cc7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  0.1769435280110893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from statistics import median\n",
    "\n",
    "array_of_Y = []\n",
    "\n",
    "for i in range(0, 30):\n",
    "  data_point_i = x[:, list_selected_columns[i]]\n",
    "  target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
    "  array_of_Y.append(target_y_i)\n",
    "  \n",
    "  \n",
    "predicted_array_of_target_y = np.array(array_of_Y)\n",
    "predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
    "\n",
    "# print(predicted_array_of_target_y.shape)\n",
    "\n",
    "# Now to calculate MSE, first calculate the Median of Predicted Y\n",
    "# passing axis=1 will make sure the medians are computed along axis=1\n",
    "median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
    "median_predicted_y.shape\n",
    "\n",
    "print(\"MSE : \", mean_squared_error(y, median_predicted_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e35366",
   "metadata": {},
   "source": [
    "# Step - 3 of Task-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3385e3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_oob_score is  14.42942195716525\n"
     ]
    }
   ],
   "source": [
    "# First noting that our earlier definded variable list_selected_row and list_selected_columns \n",
    "# which has the list of selected rows and columns\n",
    "# e.g. list_selected_row is a 2D array of the form [[], [], []...] each inner-array represnting selected row numbers\n",
    "# for a specific sample. and len(list_selected_row) is 30 reprsenting the 30 samples we have selected for bootstrapping\n",
    "# print(\"list_selected_row[10] \", list_selected_row[10])\n",
    "# print(list_selected_columns)\n",
    "\n",
    "y_predicted_oob_median_list = []\n",
    "\n",
    "for i in range(0, 506):\n",
    "  indices_for_oob_models = []\n",
    "  \n",
    "  # For each of i-th row I shall build a list, of sample size 30\n",
    "  # ONLY condition being that this i-th row should not be part of the list_selected_row[i-th]\n",
    "  # e.g. say for i = 469 and index_oob in below loop is 10 then \n",
    "  # list_selected_row[10] (which is an array of row-numbers) should not contain the 469-th row\n",
    "  for index_oob in range(0, 30):\n",
    "    if i not in list_selected_row[index_oob]:\n",
    "      indices_for_oob_models.append(index_oob)\n",
    "      \n",
    "  y_predicted_oob_list = []\n",
    "  \n",
    "  for oob_model_index in indices_for_oob_models:\n",
    "    model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
    "    \n",
    "    row_oob = x[i]\n",
    "    # print('oob_model_index ', oob_model_index)\n",
    "    \n",
    "    # Now extract ONLY those specific columns/featues that were selected during the bootstrapping\n",
    "    x_oob_data_point = [row_oob[columns] for columns in list_selected_columns[oob_model_index] ]\n",
    "    # print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
    "    x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
    "    \n",
    "    y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
    "    y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
    "    # \n",
    "  y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
    "  \n",
    "  y_predicted_median = np.median(y_predicted_oob_list)\n",
    "  y_predicted_oob_median_list.append(y_predicted_median)\n",
    "  \n",
    "\n",
    "def calculate_oob_score(num_rows):\n",
    "  oob_score = 0\n",
    "  for i in range(0, num_rows):\n",
    "    oob_score += ((y[i] - y_predicted_oob_median_list[i] ) ** 2)\n",
    "  final_oob_score = oob_score/506\n",
    "  return final_oob_score\n",
    "\n",
    "print(\"final_oob_score is \", calculate_oob_score(506))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cb18b2",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc38159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09317317193675886, 17.875986793431114)\n"
     ]
    }
   ],
   "source": [
    "# Function to build the entire bootstrapping steps that we did above and\n",
    "# Reurning from the function the MSE and oob score\n",
    "def bootstrapping_and_oob(x, y):\n",
    "\n",
    "  # Use generating_samples function to create 30 samples \n",
    "  # store these created samples in a list\n",
    "  list_input_data =[]\n",
    "  list_output_data =[]\n",
    "  list_selected_row= []\n",
    "  list_selected_columns=[]\n",
    "  \n",
    "  for i in range (0, 30):\n",
    "    a, b, c, d = generating_samples(x, y)\n",
    "    list_input_data.append(a)\n",
    "    list_output_data.append(b)\n",
    "    list_selected_row.append(c)\n",
    "    list_selected_columns.append(d)\n",
    "  \n",
    "  # building regression trees\n",
    "  list_of_all_models_decision_tree = []\n",
    "  for i in range(0, 30):\n",
    "    model_i = DecisionTreeRegressor(max_depth=None)\n",
    "    model_i.fit(list_input_data[i], list_output_data[i])\n",
    "    list_of_all_models_decision_tree.append(model_i)\n",
    "  \n",
    "  # calculating MSE\n",
    "  array_of_Y = []\n",
    "\n",
    "  for i in range(0, 30):\n",
    "    data_point_i = x[:, list_selected_columns[i]]\n",
    "    target_y_i = list_of_all_models_decision_tree[i].predict(data_point_i)\n",
    "    array_of_Y.append(target_y_i)\n",
    "    \n",
    "    \n",
    "  predicted_array_of_target_y = np.array(array_of_Y)\n",
    "  predicted_array_of_target_y = predicted_array_of_target_y.transpose()\n",
    "\n",
    "  # print(predicted_array_of_target_y.shape)\n",
    "\n",
    "  # Now to calculate MSE, first calculate the Median of Predicted Y\n",
    "  # passing axis=1 will make sure the medians are computed along axis=1\n",
    "  median_predicted_y = np.median(predicted_array_of_target_y, axis=1)\n",
    "  \n",
    "  # And now the final MSE\n",
    "  MSE = mean_squared_error(y, median_predicted_y )\n",
    "  \n",
    "  # Calculating OOB Score\n",
    "  y_predicted_oob_median_list = []\n",
    "\n",
    "  for i in range(0, 506):\n",
    "    indices_for_oob_models = []\n",
    "    \n",
    "    # For each of i-th row I shall build a list of sample size 30\n",
    "    # ONLY condition being that this ith row should not be part of\n",
    "    # the list_selected_row\n",
    "    for index_oob in range(0, 30):\n",
    "      if i not in list_selected_row[index_oob]:\n",
    "        indices_for_oob_models.append(index_oob)\n",
    "        \n",
    "    y_predicted_oob_list = []\n",
    "    \n",
    "    for oob_model_index in indices_for_oob_models:\n",
    "      model_oob = list_of_all_models_decision_tree[oob_model_index]\n",
    "      \n",
    "      row_oob = x[i]\n",
    "      # print('oob_model_index ', oob_model_index)\n",
    "      \n",
    "      x_oob_data_point = [row_oob[col] for col in list_selected_columns[oob_model_index] ]\n",
    "      # print('np.array(x_oob_data_point) ', np.array(x_oob_data_point))\n",
    "      x_oob_data_point = np.array(x_oob_data_point).reshape(1, -1)\n",
    "      \n",
    "      y_predicted_oob_data_point = model_oob.predict(x_oob_data_point)\n",
    "      y_predicted_oob_list.append(y_predicted_oob_data_point)\n",
    "      # \n",
    "    y_predicted_oob_list = np.array(y_predicted_oob_list)\n",
    "    \n",
    "    y_predicted_median = np.median(y_predicted_oob_list)\n",
    "    y_predicted_oob_median_list.append(y_predicted_median)\n",
    "    \n",
    "\n",
    "  oob_score = 0\n",
    "\n",
    "  for i in range(0, 506):\n",
    "    # oob_score = (oob_score + (y[i] - y_predicted_oob_median_list[i] ) ** 2)\n",
    "    # 13.828377285079045\n",
    "    oob_score += (y[i] - y_predicted_oob_median_list[i] ) ** 2\n",
    "\n",
    "  final_oob_score = oob_score/506\n",
    "  \n",
    "  return MSE, final_oob_score\n",
    "\n",
    "print(bootstrapping_and_oob(x, y))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61c470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amitk\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\amitk\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence_interval_mse_35  (0.07894844955950589, 0.15868524393415223)\n",
      "confidence_interval_oob_score_35  (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "x=boston.data #independent variables\n",
    "y=boston.target #target variable\n",
    "\n",
    "mse_boston_35_times_arr = []\n",
    "oob_score_boston_35_times_arr = []\n",
    "\n",
    "# Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score\n",
    "for i in range(0, 35):\n",
    "  mse, oob_score = bootstrapping_and_oob(x, y)\n",
    "  mse_boston_35_times_arr.append(mse)\n",
    "  oob_score_boston_35_times_arr.append(oob_score)\n",
    "\n",
    "\n",
    "mse_boston_35_times_arr = np.array(mse_boston_35_times_arr)\n",
    "oob_score_boston_35_times_arr = np.array(oob_score_boston_35_times_arr)\n",
    "\n",
    "confidence_level = 0.95\n",
    "degrees_of_freedom = 34 # sample.size - 1\n",
    "\n",
    "mean_of_sample_mse_35 = np.mean(mse_boston_35_times_arr)\n",
    "standard_error_of_sample_mse_35 = scipy.stats.sem(mse_boston_35_times_arr)\n",
    "\n",
    "\n",
    "# Per document - https://www.kite.com/python/answers/how-to-compute-the-confidence-interval-of-a-sample-statistic-in-python\n",
    "# confidence_interval = scipy.stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n",
    "confidence_interval_mse_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_mse_35, standard_error_of_sample_mse_35 )\n",
    "print(\"confidence_interval_mse_35 \", confidence_interval_mse_35)\n",
    "\n",
    "# Now calculate confidence inter for oob score\n",
    "mean_of_sample_oob_score_35 = np.mean(oob_score_boston_35_times_arr)\n",
    "standard_error_of_sample_oob_score_35 = scipy.stats.sem(oob_score_boston_35_times_arr)\n",
    "\n",
    "confidence_interval_oob_score_35 = scipy.stats.t.interval(confidence_level, degrees_of_freedom, mean_of_sample_oob_score_35, standard_error_of_sample_oob_score_35 )\n",
    "print(\"confidence_interval_oob_score_35 \", confidence_interval_oob_score_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d952f",
   "metadata": {},
   "source": [
    "# Task 3 (send query point \"xq\" to 30 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40964cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_y_given_x_bootstrap(x_query):\n",
    "  y_predicted_array_30_sample = []\n",
    "  \n",
    "  for i in range(0, 30):\n",
    "    model_i = list_of_all_models_decision_tree[i]\n",
    "    # Extract x for ith data point with specific number of featues from list_selected_columns\n",
    "    x_data_point_i = [x_query[column] for column in list_selected_columns[i]]\n",
    "    x_data_point_i = np.array(x_data_point_i).reshape(1, -1)\n",
    "    y_predicted_i = model_i.predict(x_data_point_i)\n",
    "    y_predicted_array_30_sample.append(y_predicted_i)\n",
    "    \n",
    "  y_predicted_array_30_sample = np.array(y_predicted_array_30_sample)\n",
    "  y_predicted_median = np.median(y_predicted_array_30_sample)\n",
    "  return y_predicted_median\n",
    "\n",
    "\n",
    "xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
    "y_predicted_for_xq = predict_y_given_x_bootstrap(xq)\n",
    "y_predicted_for_xq    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcb390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
